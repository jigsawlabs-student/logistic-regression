{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll introduce the fundamentals of probability.  Probability is at the basis for how machine learning classifiers like a bayes classifier and logistic regression classifiers train their hypothesis function.  It makes sense, probability allows to calculate the likelihood that an event will happen, which is the fundamental task of classification.  Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With probability we can take the perspective that we are running an experiment, or a trial.    For example, let's say that our experiment is a single roll of a six sided die.  Now let's set some parameters to this experiment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sample Space - The sample space is the set of all possible outcomes of an experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So for this experiment it, we can define our sample space as: $S =  \\{1, 2, 3, 4, 5, 6\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Event space - The event space is the set of outcomes that we care about.  The event space is a subset of the sample space, $E \\subseteq S$.\n",
    "\n",
    "> For example when we roll the dice, let's say that we care about when we get an even number.  \n",
    "> * Then the event space $E$, is:\n",
    "> * $E = \\{2, 4, 6\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Probability - The $P(E)$ is the fraction of times E occurs if we perform infinite experiments.  Mathematically, we can write this as the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $P(E) = \\lim_{n\\to \\infty} \\frac{n(E)}{n}$, where n is the number of experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we perform the experiment many times, and we see that half the times the die lands on 2, 4, or 6,  then $P(E) = .5$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Axioms of Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are a couple of rules that follow from the above definitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $P(S) = 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So applied to our example, this just says that probability of rolling a number 1 through 6 is 1, as it must occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $0 \\leq P(E) \\leq 1 $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This should make sense.  If we define probability as the number of times an event occurs divided by the number of trials,  then P(E) cannot exceed 1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  $P(E \\cup F) = P(E) + P(F) - P(E \\cap F)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This says, to calculate the probability of either event E or F occurring, we add the probability of each event, and subtract the probability of both events occurring. \n",
    "\n",
    "So for example if E = {2, 4, 6}, and F = {5, 6}, and the probability of rolling any individual number is 1/6, then:\n",
    "\n",
    "$P(E \\cup F) = \\frac{3}{6} + \\frac{2}{6} - \\frac{1}{6} = \\frac{4}{6}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two more rules to know:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $P(E^c) = 1 - P(E)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $E^c$ just means E complement.  Here we are saying that the probability of an event not occurring is probability that it occurs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For example, let's define $G = E \\cup F$, as defined above.  Then $G^c = 1 - \\frac{4}{6} = \\frac{2}{6}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equally likely outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we are in a situation where each outcome in a sample space is equally likely.  If that is the case, then the following follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $P(Each Outcome) = \\frac{1}{S}$\n",
    "\n",
    "* $P(E) = \\frac{\\text{num outcomes in E}}{\\text{num outcomes in S}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources \n",
    "\n",
    "[Stanford Probability Problems](http://web.stanford.edu/class/cs109/psets/pset2.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
