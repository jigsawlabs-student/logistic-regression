{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Metrics Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll review our various metrics by working with our breast cancer dataset.  Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin by loading our data and creating a dataframe to represent our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.DataFrame(cancer['data'], columns = cancer['feature_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a series for our targets, but need to reverse the feature and target data, because, confusingly in this dataset 1 represents benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer['target_names'] # array(['malignant', 'benign'], dtype='<U9')\n",
    "y = pd.Series((cancer['target'] == 0).astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33            184.6   \n",
       "1                 0.05667  ...         24.99          23.41            158.8   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have assigned our data, let's scale our feature data,X, and assign the scaled data to a dataframe.  Assign the dataframe to `X_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_df = pd.DataFrame(X_scaled, columns = cancer['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>2.255747</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886690</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-0.868652</td>\n",
       "      <td>...</td>\n",
       "      <td>1.805927</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0     1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
       "1     1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0          3.283515        2.652874             2.532475       2.217515   \n",
       "1         -0.487072       -0.023846             0.548144       0.001392   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                2.255747  ...      1.886690      -1.359293         2.303601   \n",
       "1               -0.868652  ...      1.805927      -0.369203         1.535126   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0    2.001237          1.307686           2.616665         2.109526   \n",
       "1    1.890489         -0.375612          -0.430444        -0.146749   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0              2.296076        2.750622                 1.937015  \n",
       "1              1.087084       -0.243890                 0.281190  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df[:2]\n",
    "\n",
    "# \tmean radius\tmean texture\tmean perimeter\tmean area\tmean smoothness\tmean compactness\tmean concavity\tmean concave points\tmean symmetry\tmean fractal dimension\t...\tworst radius\tworst texture\tworst perimeter\tworst area\tworst smoothness\tworst compactness\tworst concavity\tworst concave points\tworst symmetry\tworst fractal dimension\n",
    "# 0\t1.097064\t-2.073335\t1.269934\t0.984375\t1.568466\t3.283515\t2.652874\t2.532475\t2.217515\t2.255747\t...\t1.886690\t-1.359293\t2.303601\t2.001237\t1.307686\t2.616665\t2.109526\t2.296076\t2.750622\t1.937015\n",
    "# 1\t1.829821\t-0.353632\t1.685955\t1.908708\t-0.826962\t-0.487072\t-0.023846\t0.548144\t0.001392\t-0.868652\t...\t1.805927\t-0.369203\t1.535126\t1.890489\t-0.375612\t-0.430444\t-0.146749\t1.087084\t-0.243890\t0.281190\n",
    "# 2 rows Ã— 30 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, split the data into training, validation, and test sets and apply a stratified split.  Create a 60-20-20 split, and set the `random_state = 1` for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y,\n",
    "                                                    stratify = y,\n",
    "                                                    random_state = 1, test_size = .4)\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_test, y_test, \n",
    "                                                    test_size = .5, \n",
    "                                                    stratify = y_test,\n",
    "                                                    random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((341, 30), (114, 30), (114, 30))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_validate.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a logistic regression model and score the accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train).score(X_validate, y_validate)\n",
    "\n",
    "# 0.9736842105263158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a second logistic regression model with a `class_weight` of `balanced`.  Score the model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "balanced_lr = LogisticRegression()\n",
    "balanced_lr.fit(X_train, y_train).score(X_validate, y_validate)\n",
    "# 0.9736842105263158"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the `f1_score` of our two models.  First use sklearn to calculate the `f1_score` of the model with the original sample weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.963855421686747"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score sample model \n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_validate, lr_model.predict(X_validate))\n",
    "\n",
    "# 0.963855421686747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.963855421686747"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score balanced model \n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_validate, balanced_lr.predict(X_validate))\n",
    "\n",
    "# 0.963855421686747"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that `f_1_score` is a harmonic mean of the precision and recall.  \n",
    "\n",
    "Now let's see how the two models perform on the auc_score, which remember calculates how our models order the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9692460317460317"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate roc of model with original sample weights\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    " \n",
    "\n",
    "sample_roc_auc = roc_auc_score(y_validate, model.predict(X_validate))\n",
    "sample_roc_auc\n",
    "\n",
    "# 0.9692460317460317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9692460317460317"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate balanced model \n",
    "\n",
    "balanced_roc_auc = roc_auc_score(y_validate, balanced_model.predict(X_validate))\n",
    "balanced_roc_auc\n",
    "\n",
    "# 0.9692460317460317"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that both models perform the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try Under-Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We'll code this section for you, as it's a new technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try a different technique.  So far we have trained a model to handle imbalanced data by weighing the samples from the under-represented class more highly.  A different technique is simply to reduce the over-represented, that is undersample our dataset.  Let's try this.\n",
    "\n",
    "We'll begin by assigning our X and y training data into the same dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_X_y = X_train.assign(y = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll shuffle our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_sample = combined_X_y.sample(frac=1, random_state = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we'll select just the positive samples from our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 31)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancerous_combined = combined_sample[combined_sample['y'] == 1]\n",
    "cancerous_combined.shape\n",
    "\n",
    "# (127, 31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then select the benign observations, but limit them to the same number of observations as our cancerous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127, 31)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benign_combined = combined_sample[combined_sample['y'] == 0][:127]\n",
    "benign_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now combine the two datasets together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "even_df = pd.concat([cancerous_combined, benign_combined])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's check that we have an equal number of positive and negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_df.y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can shuffle our data so that we do not have all positive samples followed by all negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_even_df = even_df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we retrain our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "X_even = shuffled_even_df.drop('y', axis = 1)\n",
    "y_even = shuffled_even_df['y']\n",
    "model.fit(X_even, y_even).score(X_validate, y_validate)\n",
    "\n",
    "# 0.9473684210526315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9402597402597402"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(model.predict(X_validate), y_validate)\n",
    "# 0.9402597402597402"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So we see a slight decrease to balancing our data (0.9692460317460317 was our previous high score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how a random forest classifier performs on our datasets.  First, let's try it on our original training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Set the number of estimators to 50, `min_samples_leaf` as `7`, `max_features = 'log2'`and `class_weight = 'balanced'.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', max_features='log2',\n",
       "                       min_samples_leaf=7, n_estimators=50, random_state=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(class_weight='balanced', max_features='log2',\n",
    "                        min_samples_leaf=7, n_estimators=50, random_state=1)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "# RandomForestClassifier(class_weight='balanced', max_features='log2',\n",
    "#                        min_samples_leaf=7, n_estimators=50, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the `roc_auc_score` using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9217532467532468"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(rfc.predict(X_validate), y_validate)\n",
    "\n",
    "# 0.9217532467532468"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ok, so not quite as good as our logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how a model trained on our balanced dataset performs.  Use the same hyperparameters, but do not set `class_weight = 'balanced'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='log2', min_samples_leaf=7, n_estimators=50,\n",
       "                       random_state=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_balanced = RandomForestClassifier(max_features='log2', min_samples_leaf=7, n_estimators=50,\n",
    "                        random_state=1)\n",
    "rfc_balanced.fit(X_train, y_train)\n",
    "# RandomForestClassifier(max_features='log2', min_samples_leaf=7, n_estimators=50,\n",
    "#                        random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Check the `roc_auc_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9479729729729729"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(rfc_balanced.predict(X_validate), y_validate)\n",
    "# 0.9479729729729729"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So still not as good as our logistic regression models with a score of .96."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to lean towards catching cancer cases, as opposed to worrying about false negatives.  Let's plot our precision recall curves of the non-balanced logistic regression model to get a sense of a threshold.  Use the validation data to find the threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((341, 30), (114, 30))"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_validate, lr_model.predict_proba(X_validate)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x125a28f10>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot curve here\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(x = thresholds, y = precision[1:], label = 'precision')\n",
    "plt.scatter(x = thresholds, y = recall[1:], label = 'recall')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./precision-recall-metrics.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the plot above that we can achieve a high level of recall, without a hardly any drop to precision.  Of course we don't want to just to classify everything as cancerous.  That wouldn't be so helpful.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's experiment with a threshold of .2 to see how we perform.\n",
    "\n",
    "> After setting a threshold, check the precision score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8913043478260869"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "threshold = .2\n",
    "precision_score(y_validate, lr_model.predict_proba(X_validate)[:, 1] > threshold)\n",
    "\n",
    "# 0.8913043478260869"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Then check the recall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9761904761904762"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "recall_with_threshold = recall_score(y_validate, lr_model.predict_proba(X_validate)[:, 1] > threshold)\n",
    "recall_with_threshold\n",
    "\n",
    "# 0.9761904761904762"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that if we set a threshold at .12, we can capture almost all of the positive cases, and still maintain a precision score of .91.  Let's do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's combine our training and validation data, so we can our logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_combined = pd.concat([X_train, X_validate])\n",
    "y_combined = pd.concat([y_train, y_validate]) \n",
    "lr_combined = LogisticRegression().fit(X_combined, y_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's practice *undersampling* our data with this new dataset.  We'll combine our features and targets into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>-0.144078</td>\n",
       "      <td>0.916946</td>\n",
       "      <td>-0.196849</td>\n",
       "      <td>-0.232332</td>\n",
       "      <td>-0.277565</td>\n",
       "      <td>-0.698760</td>\n",
       "      <td>-0.741488</td>\n",
       "      <td>-0.631673</td>\n",
       "      <td>-0.538947</td>\n",
       "      <td>-0.678694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555750</td>\n",
       "      <td>-0.288363</td>\n",
       "      <td>-0.265064</td>\n",
       "      <td>-0.472051</td>\n",
       "      <td>-0.652457</td>\n",
       "      <td>-0.802570</td>\n",
       "      <td>-0.652707</td>\n",
       "      <td>-0.418610</td>\n",
       "      <td>-0.798864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1.287353</td>\n",
       "      <td>-0.504892</td>\n",
       "      <td>1.212267</td>\n",
       "      <td>1.200527</td>\n",
       "      <td>0.643316</td>\n",
       "      <td>0.107247</td>\n",
       "      <td>0.714386</td>\n",
       "      <td>0.973229</td>\n",
       "      <td>0.563638</td>\n",
       "      <td>-0.094641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126566</td>\n",
       "      <td>1.135996</td>\n",
       "      <td>1.175019</td>\n",
       "      <td>0.786039</td>\n",
       "      <td>-0.160085</td>\n",
       "      <td>0.263919</td>\n",
       "      <td>0.803870</td>\n",
       "      <td>-0.010929</td>\n",
       "      <td>0.034035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "545    -0.144078      0.916946       -0.196849  -0.232332        -0.277565   \n",
       "121     1.287353     -0.504892        1.212267   1.200527         0.643316   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "545         -0.698760       -0.741488            -0.631673      -0.538947   \n",
       "121          0.107247        0.714386             0.973229       0.563638   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "545               -0.678694  ...       0.555750        -0.288363   -0.265064   \n",
       "121               -0.094641  ...      -0.126566         1.135996    1.175019   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "545         -0.472051          -0.652457        -0.802570   \n",
       "121          0.786039          -0.160085         0.263919   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  y  \n",
       "545             -0.652707       -0.418610                -0.798864  0  \n",
       "121              0.803870       -0.010929                 0.034035  1  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_y_combined = X_combined.assign(y = y_combined)\n",
    "X_y_combined[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then separate out the observations with a positive target value, and negative target value accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_positive = X_y_combined[X_y_combined['y'] == 1]\n",
    "X_y_negative = X_y_combined[X_y_combined['y'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((169, 31), (286, 31))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_y_positive.shape, X_y_negative.shape\n",
    "\n",
    "# ((169, 31), (286, 31))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that to get them even, we should shuffle our negative data and select the first 169 samples.\n",
    "\n",
    "> Set the random_state = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_X_y_neg = X_y_negative.sample(frac = 1, random_state = 1)[:169]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then combine this with the dataframe of positive values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_y_combined_even = pd.concat([X_y_positive, shuffled_X_y_neg])\n",
    "X_y_combined_even['y'].mean()\n",
    "\n",
    "# 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And shuffle the data so that we do not have all of the positive data first.\n",
    "\n",
    "> Set random_state = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_combined_even_shuffled = X_y_combined_even.sample(frac = 1, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a model another logistic regression model with our undersampled data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_undersampled =  X_y_combined_even_shuffled.drop('y', axis = 1)\n",
    "y_undersampled = X_y_combined_even_shuffled['y']\n",
    "lrm_combined_undersampled = LogisticRegression().fit(X_undersampled, y_undersampled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9931215198165738"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, lrm_combined_undersampled.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# 0.9931215198165738"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's keep the same threshold of .2, and make predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8913043478260869"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "undersampled_predictions = lrm_combined_undersampled.predict_proba(X_test)[:, 1] > .2\n",
    "\n",
    "precision_test = precision_score(y_test, undersampled_predictions)\n",
    "precision_test\n",
    "\n",
    "# 0.8913043478260869"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9534883720930233"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_test = recall_score(y_test, undersampled_predictions)\n",
    "recall_test\n",
    "\n",
    "# 0.9534883720930233"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that with the same threshold our precision decreases slightly on the test set, but we can capture 95 percent of positive cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources \n",
    "[Using Machine Learning Metrics](https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Smote](https://rikunert.com/SMOTE_explained)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
